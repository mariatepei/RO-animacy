{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfcd9afb",
   "metadata": {},
   "source": [
    "# Automatic animacy classification for Romanian nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed679e80",
   "metadata": {},
   "source": [
    "Import necessary libraries and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1265d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import re\n",
    "import csv\n",
    "import spacy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34640526",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06c29e",
   "metadata": {},
   "source": [
    "Our proposed classifier distinguishes between two classes of Romanian nouns, human and non-human, by working with lemmas from a word list as opposed to tokens from a large annotated corpus. We use a seed set of nouns labeled with animacy information derived from Romanian WordNet and make use of the associations encoded in a pretrained word embedding model to train a classifier that can generalize beyond the labeled seed nouns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cbf21",
   "metadata": {},
   "source": [
    "We first derived two sets of Romanian nouns from WordNet, attempting to encompass as many tokens that can be labelled as either human or non-human. To this end, we first identified two high-order hypernyms in the WordNet hierarchy that can act as either animate or inanimate targets for each subsequent set of words (namely *ființă umană* 'human being' and *artefact* 'artefact'). Then, we used Open Multilingual WordNet (OMW) to generate lists of hyponyms for each of the two high-order target synsets, thus resulting in two different sets of words, one containing nouns with the semantic feature [+Human] and the other containing the semantic feature [+Non-Human]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43e3a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function provided by RoWordNet API author\n",
    "# https://github.com/dumitrescustefan/RoWordNet/tree/master\n",
    "def get_hyponyms(synset):\n",
    "    hyponyms = set()\n",
    "    for hyponym in synset.hyponyms():\n",
    "        hyponyms |= set(get_hyponyms(hyponym))\n",
    "    return hyponyms | set(synset.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64dc2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sysnsets | lemmas below target hypernyms\n",
    "human_target = wn.synsets('făptură', lang = 'ron', pos = wn.NOUN)\n",
    "non_animate_target = wn.synsets('obiect', lang = 'ron', pos = wn.NOUN)\n",
    "list_of_animates = []\n",
    "list_of_inanimates = []\n",
    "for synset in wn.synsets('om', lang = 'ron', pos = wn.NOUN):\n",
    "    hyponyms = get_hyponyms(synset)\n",
    "    for item in hyponyms: #item is a synset object\n",
    "        for lemma in item.lemmas():\n",
    "            list_of_animates.append(lemma.name())\n",
    "\n",
    "for synset in wn.synsets('artifact', lang = 'ron', pos = wn.NOUN):\n",
    "    inanimate_hyponyms = get_hyponyms(synset)\n",
    "    for item in inanimate_hyponyms:\n",
    "        for lemma in item.lemmas():\n",
    "            list_of_inanimates.append(lemma.name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27605d7e",
   "metadata": {},
   "source": [
    "Secondly, we extracted corresponding vectors for each word in this seed set using a set of pre-trained word embeddings for Romanian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f38ace46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained vectors\n",
    "# http://89.38.230.23/word_embeddings/\n",
    "wv_from_text = KeyedVectors.load_word2vec_format('.\\corola.300.20.vec', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a48a0030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with all tokens (animate + inanimate)\n",
    "list_of_lines = []\n",
    "all_tokens = list_of_animates + list_of_inanimates\n",
    "newline = '\\n'\n",
    "\n",
    "# create an np array containing tokens, vectors and animacy labels\n",
    "for token in all_tokens:\n",
    "    if token in wv_from_text:\n",
    "        if token in list_of_animates:\n",
    "            animacy_label = 'animate'\n",
    "        else:\n",
    "            animacy_label = 'inanimate'\n",
    "        vector = wv_from_text.__getitem__(token)\n",
    "        line_str = animacy_label + ',' + np.array2string(vector, max_line_width=np.inf) + ',' + token\n",
    "        line_list = line_str.split(',')\n",
    "        list_of_lines.append(line_list)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# writing the list of lists to a csv file\n",
    "outfilename = \"vectors1.csv\"\n",
    "with open(outfilename, \"w\") as outfile:\n",
    "    for row in list_of_lines:\n",
    "        line = f'{\",\".join(row)}{newline}'\n",
    "        outfile.write(line)\n",
    "        \n",
    "words_data = pd.read_csv('vectors1.csv', encoding='latin-1', header = None)\n",
    "words_data.columns = ['animacy label', 'vector str', 'word']\n",
    "words_data.head()\n",
    "words_data.shape[0]\n",
    "\n",
    "# convert column 1 to np.ndarray again\n",
    "words_data['vector'] = words_data['vector str'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "\n",
    "# encoding the label column\n",
    "words_data['animacy label'] = words_data['animacy label'].map({'animate':1,'inanimate':0})\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split (words_data['vector'], words_data['animacy label'] , test_size=0.2)\n",
    "vector_length = words_data['vector'][0].shape[0]\n",
    "\n",
    "# create the X_train_vectors array\n",
    "X_train_vectors = np.zeros((len(X_train), vector_length))\n",
    "i=0\n",
    "for index, row in X_train.iteritems():\n",
    "    vector = row\n",
    "    X_train_vectors[i] = vector\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb6850",
   "metadata": {},
   "source": [
    "### Training the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d945d14",
   "metadata": {},
   "source": [
    "We applied three different classifiers to the task: Random Forest (RF), Multi-layer Perceptron (MLP) and k-nearest neighbours (KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c37d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_vectors, y_train)\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "mlp_model = mlp.fit(X_train_vectors, y_train)\n",
    "\n",
    "knn_model = KNeighborsClassifier().fit(X_train_vectors, y_train)\n",
    "\n",
    "# feature vectors from testing data\n",
    "X_test_vectors = np.zeros((len(X_test), vector_length))\n",
    "for i, vector in enumerate(X_test):\n",
    "    X_test_vectors[i] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37da3b",
   "metadata": {},
   "source": [
    "### Predict animacy labels using trained classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0959cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test_vectors)\n",
    "y_pred_mlp = mlp_model.predict(X_test_vectors)\n",
    "y_pred_knn = knn_model.predict(X_test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209da2e",
   "metadata": {},
   "source": [
    "### Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b228f746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.921 / Recall: 0.797 / Accuracy: 0.873\n",
      "Precision: 0.863 / Recall: 0.866 / Accuracy: 0.873\n",
      "Precision: 0.742 / Recall: 0.827 / Accuracy: 0.784\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))\n",
    "\n",
    "precision_mlp = precision_score(y_test, y_pred_mlp)\n",
    "\n",
    "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_mlp, 3), round(recall_mlp, 3), round((y_pred_mlp == y_test).sum()/len(y_pred_mlp), 3)))\n",
    "\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision_knn, 3), round(recall_knn, 3), round((y_pred_knn == y_test).sum()/len(y_pred_knn), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00e3e4",
   "metadata": {},
   "source": [
    "### Evaluation on natural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "267aceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_file(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "        text = infile.read()\n",
    "\n",
    "        # Remove punctuation and numbers, keep words and spaces\n",
    "        preprocessed_text = ''.join(char for char in text if char.isalpha() or char.isspace())\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(preprocessed_text)\n",
    "\n",
    "def tokenize_preprocessed_text(preprocessed_text):\n",
    "    tokens = nltk.word_tokenize(preprocessed_text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e7ae5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text_file('evaluation.txt', 'evaluation_clean.txt')\n",
    "with open('evaluation_clean.txt', 'r', encoding = 'utf8') as infile:\n",
    "    clean_text = infile.read()\n",
    "    tokens = tokenize_preprocessed_text(clean_text)\n",
    "\n",
    "ro_model = spacy.load(\"ro_core_news_sm\")\n",
    "\n",
    "# list of tokens into single string\n",
    "tokenized_text = \" \".join(tokens)\n",
    "\n",
    "# extract nouns\n",
    "doc = ro_model(tokenized_text)\n",
    "nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "#len(nouns)\n",
    "\n",
    "# process list of nouns to expected data format for rf_model (2D np array)\n",
    "\n",
    "# extract vectors for the list of nouns\n",
    "novel_noun_vectors = []\n",
    "for noun in nouns:\n",
    "    if noun in wv_from_text:\n",
    "        word_vector = wv_from_text[noun]\n",
    "        novel_noun_vectors.append(word_vector)\n",
    "\n",
    "# join the nouns and vectors\n",
    "novel_noun_vectors = np.array(novel_noun_vectors)\n",
    "\n",
    "# pass nouns to RF classifier\n",
    "novel_noun_predictions = rf_model.predict(novel_noun_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84b176ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows for each label:\n",
      "0     87.211740\n",
      "1      7.337526\n",
      "oc     5.450734\n",
      "Name: annotated, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('noun_prediction_annotation.csv', encoding = 'utf8')\n",
    "\n",
    "label_counts = df['annotated'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Percentage of rows for each label:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d5dbfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     832\n",
       "1      70\n",
       "oc     52\n",
       "Name: annotated, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['annotated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0d91e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop lines labelled as other class (not nouns, i.e. POS-tagging errors)\n",
    "df = df[df.annotated != 'oc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f327588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    832\n",
       "1     70\n",
       "Name: annotated, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['annotated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e152b4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[514 318]\n",
      " [ 43  27]]\n",
      "False Negatives: 43\n",
      "True negatives: 27\n",
      "True positives: 514\n",
      "Correct Predictions: 541\n",
      "False Positives: 318\n",
      "\n",
      "Accuracy: 0.5997782705099778\n",
      "Precision: 0.0782608695652174\n",
      "Recall: 0.38571428571428573\n",
      "F1 Score: 0.13012048192771086\n"
     ]
    }
   ],
   "source": [
    "# # Load the CSV file\n",
    "# file_path = 'predicted_lables_novel_nouns.csv'  \n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean up NaN values\n",
    "df = df.dropna()\n",
    "# Generate the confusion matrix\n",
    "y_true = df['annotated'].astype('int')\n",
    "y_pred = df['predicted']\n",
    "\n",
    "# Define the labels for confusion matrix\n",
    "labels = ['False Negative', 'Correct Prediction', 'False Positive']\n",
    "\n",
    "# Create the confusion matrix\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "false_positive = confusion[0, 1]\n",
    "correct_prediction = int(confusion[1, 1]) + int(confusion[0,0])\n",
    "false_negative = confusion[1, 0]\n",
    "true_negative = confusion[1,1]\n",
    "true_positive = confusion[0,0]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "print(f\"False Negatives: {false_negative}\")\n",
    "print(f'True negatives: {true_negative}')\n",
    "print(f\"True positives: {true_positive}\")\n",
    "print(f\"Correct Predictions: {correct_prediction}\")\n",
    "print(f\"False Positives: {false_positive}\")\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
